{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - (E7.1)\n",
    "\n",
    "The required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T18:25:16.407943304Z",
     "start_time": "2023-04-30T18:25:16.348173176Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from utilities.activation_functions import hardlims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 1\n",
    "\n",
    "Let's define the problem variables. We then convert the squares into vectors, by scanning them column by column. White squares are represented as $-1$, conversely blue ones as $1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T18:25:16.430954155Z",
     "start_time": "2023-04-30T18:25:16.371484080Z"
    }
   },
   "outputs": [],
   "source": [
    "p1 = np.array([-1, -1, 1, 1]).reshape(-1, 1)\n",
    "p2 = np.array([1, 1, -1, 1]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orthogonality can be easily checked by recalling that two vectors are orthogonal if:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\textbf{p}_1^T \\cdot \\textbf{p}_2 = 0\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T18:25:16.431282707Z",
     "start_time": "2023-04-30T18:25:16.371704123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product:  -2\n"
     ]
    }
   ],
   "source": [
    "# Orthogonality check\n",
    "print(\"Dot product: \", np.squeeze(np.dot(p1.transpose(), p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product is not zero, therefore **the two vectors are not orthogonal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 2\n",
    "\n",
    "Using the Hebb rule in the case of __autoassociative network__, thus the output to each input being the input itself, the weight matrix is computed as:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "    \\textbf{W} = \\textbf{p}_1\\textbf{p}_1^T + \\textbf{p}_2\\textbf{p}_2^T = \\textbf{P}\\textbf{P}^T\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T18:25:16.432705051Z",
     "start_time": "2023-04-30T18:25:16.377252840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hebb W matrix:\n",
      " [[ 2  2 -2  0]\n",
      " [ 2  2 -2  0]\n",
      " [-2 -2  2  0]\n",
      " [ 0  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "# Weight matrix\n",
    "W = np.dot(p1, p1.transpose()) + np.dot(p2, p2.transpose())\n",
    "print(\"Hebb W matrix:\\n\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Point 3\n",
    "\n",
    "Let us define the test input pattern $\\textbf{p}_t$:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "pt = np.array([1, 1, 1, 1]).reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-04-30T18:25:16.441126745Z",
     "start_time": "2023-04-30T18:25:16.388099614Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Recovering the implementation of the predict function in the previous exercises, excluding the bias:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Layer output function\n",
    "def predict(p: np.ndarray, W_fun: np.ndarray):\n",
    "    return hardlims(np.dot(W_fun, p.reshape(-1, 1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-04-30T18:25:16.441367806Z",
     "start_time": "2023-04-30T18:25:16.432563354Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The prediction can be carried out as:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [ 1  1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(pt, W)\n",
    "\n",
    "print(\"Prediction: \", np.squeeze(y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-04-30T18:25:16.441616255Z",
     "start_time": "2023-04-30T18:25:16.432834206Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The prediction is **coincidentally equal** to the input $\\textbf{p}_2$, in fact the simple Hebb rule cannot assure the output will correctly match the respective input if those are not orthogonal. When the prototype input patterns are not orthogonal, the Hebb rule produces some errors, and the use of the pseudoinverse rule can reduce errors related to non-orthogonality."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
